### машин ленинг - мл
### глубокое обучение - го

#### для чего не подходит го?
- когда нужно пояснение обучения (паттерны го обычно для чела нечитабельны)
- когда классик традишнл методы лучше
- когда ошибки неприемлемы (выход моделей го не всегда предсказуем)
- когда мало входных данных

#### отличие мл от го
- в **мл** входные данные структурированы (типа табличка) - для этого кейса лучший алгоритм **gradient boosted machine** (xgboost)
- в **го** лучше неструктурированные данные (из разных признаков делать выводы) - для этого кейса **нейронки**


#### что такое нейронка (нейронная сеть)?
- вообще с чего начинается обучение?
  - входные данные (картинки, текст, аудио, итд) -> в массив чисел -> в обучающую нейронку (подходящую для кейса) -> на выходе массив чисел
- нейронка состоит из слоев
  - первый слой для входных данных
  - второй слой - скрытые слои для обучения паттернов(весов, эмбеддингов, фичи) на данных
  - третий слой выходные данные
  - <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/4/46/Colored_neural_network.svg/250px-Colored_neural_network.svg.png" width="130" height="150">

#### типы обучений
- обучение с учителем (есть данные и ответы которым должны соотвествовать результаты)
- обучение без учителя (есть данные но нет ответов, и выделям паттерны которые позволяют отличить данные, типа собаку от кошки)
- обучение с переносом (опыт и паттерны одной нейронки могут быть применимы в обучении другой нейронки)

#### когда применимо го?
- рекомендации кино, товары итд ()
- перевод языков (sequence2sequence)
- распознование голоса (sequence2sequence)
- распознование картинок (регрессия)
- нлп (классификация)

#### что такое pytorch (далее торч)? (ЧТО ТЫ ТАКОЕ????)
- самый популярный фреймворк для го
- может работать на гпу

#### что такое тензор? это фундаментальные блоки для торча
- числовой массив, числовое представление (картинку перевели в числа или выход нейронки)
- мат операции в нейронке ведутся над тензором

#### что такое скаляр?
- тензор с размерностью ноль (это одно число)

#### что такое вектор?
- это одноразмерный тензор (уже может содержать числа)
```python 
vector = torch.tensor([9, 10])
vector  # tensor([7, 7])
vector.ndim  # 1 размер равен 1
```
- вектором уже можно описать что-то, типа [кот, собака] это [9, 10] в числовом представлении 
#### как узнать размерность тензора?
- размерность можно узнать посчитав квадратные скобки с одной стороны tensor([7, 7]) - здесь размерность = 1
- пример ```torch.tensor([[7, 8], [9, 10]])``` тут = 2

#### что такое матрица?
- массив с размерностью = 2

<img src="https://forum.huawei.com/enterprise/en/data/attachment/forum/202211/07/191941v6w0x9ljxjljrifb.png" width="400" height="150">

#### нулевые тензоры
- когда нужно создать "маску" из нулей и применить ее на оригинальном тензоре, чтобы не учесть данные которые подпадают под нули
```python
zeros = torch.zeros(size=(2, 3))
# (tensor([[0., 0., 0.],
#         [0., 0., 0.]])
```
- или с единицами torch.ones(...)

#### самый популярный тип данных в торче + задать тип девайса (GPU, CPU)
- torch.float32 или torch.float
- создать тензор с типом данных: ```torch.tensor([1.0, 2.0, 3.0], dtype=torch.float32, device=None,)```

#### операции над тензором
- сложение ```torch.tensor([1, 2, 3]) + 10 = tensor([11, 12, 13])``` или torch.add
- умножение ```torch.tensor([1, 2, 3]) * 10 = tensor([10, 20, 30])``` или torch.multiply
- вычитание ```torch.tensor([1, 2, 3]) - 10 = tensor([-9, -8, -7])```
- но обычно знаками, а не фичами торча

#### в го и мл самая популярная операции над матрицами - умножение матриц
- torch.matmul()
- пример
```python
tensor = torch.tensor([1, 2, 3])
# tensor * tensor = [1*1, 2*2, 3*3] = tensor([1, 4, 9])
# torch.matmul(tensor, tensor) = [1*1 + 2*2 + 3*3] = tensor(14)
```

#### самая частая ошибка в переумножении матриц - несовпадение размерностей
- можно решить если одну из матриц транспонировать например (матрица В после транспонирования)
<img src="https://devpractice.ru/wp-content/uploads/2019/04/linal-lesson3-pic23.png" width="270" height="150">

####
####